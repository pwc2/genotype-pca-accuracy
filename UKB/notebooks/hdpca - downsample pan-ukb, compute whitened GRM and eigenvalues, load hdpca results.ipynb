{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f978ca0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hail as hl\n",
    "from hail.methods.pca import _make_tsm_from_call, _pca_and_moments\n",
    "\n",
    "hl.init(tmp_dir='gs://ukb-data/tmp/ukb-grm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed0c310",
   "metadata": {},
   "source": [
    "# On dataproc cluster\n",
    "\n",
    "## Randomly sample 10k/30k samples from UKB GT MatrixTable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dadf24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_prefix = 'gs://ukb-data/genotypes/406696-samples'\n",
    "N = 10000\n",
    "overwrite = False\n",
    "read = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a3ae4",
   "metadata": {},
   "source": [
    "Create first set of samples and write to Hail Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd2ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = hl.read_matrix_table(f'{gcs_prefix}/gt_147604_406696.mt')\n",
    "print(mt.count())\n",
    "\n",
    "samples_list = mt.s.collect()\n",
    "permuted_samples_list = list(np.random.permutation(samples_list))\n",
    "samples_to_keep_list = list(permuted_samples_list[:N])\n",
    "\n",
    "sample_set_01_ht = hl.Table.parallelize(\n",
    "    hl.literal([{'s': s} for s in samples_to_keep_list], 'array<struct{s: str}>'), \n",
    "    n_partitions=1\n",
    ")\n",
    "sample_set_01_ht = sample_set_01_ht.key_by('s')\n",
    "sample_set_01_ht = sample_set_01_ht.checkpoint(f'{gcs_prefix}/downsampled-{N}/set-01/samples.ht', \n",
    "                                               overwrite=overwrite, _read_if_exists=read)\n",
    "\n",
    "downsampled_mt = mt.semi_join_cols(sample_set_01_ht)\n",
    "downsampled_mt = downsampled_mt.repartition(8)\n",
    "downsampled_mt = downsampled_mt.checkpoint(f'{gcs_prefix}/downsampled-{N}/set-01/gt.mt', \n",
    "                                           overwrite=overwrite, _read_if_exists=read)\n",
    "print(downsampled_mt.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28d5d36",
   "metadata": {},
   "source": [
    "Create second, disjoint set of samples and write to Hail Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e5981",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_set_01_ht = hl.read_table(f'{gcs_prefix}/downsampled-{N}/set-01/samples.ht')\n",
    "\n",
    "mt = hl.read_matrix_table(f'{gcs_prefix}/gt_147604_406696.mt')\n",
    "mt = mt.anti_join_cols(sample_set_01_ht)\n",
    "print(mt.count())\n",
    "\n",
    "samples_list = mt.s.collect()\n",
    "permuted_samples_list = list(np.random.permutation(samples_list))\n",
    "samples_to_keep_list = list(permuted_samples_list[:N])\n",
    "\n",
    "sample_set_02_ht = hl.Table.parallelize(\n",
    "    hl.literal([{'s': s} for s in samples_to_keep_list], 'array<struct{s: str}>'), \n",
    "    n_partitions=1\n",
    ")\n",
    "sample_set_02_ht = sample_set_02_ht.key_by('s')\n",
    "sample_set_02_ht = sample_set_02_ht.checkpoint(f'{gcs_prefix}/downsampled-{N}/set-02/samples.ht', \n",
    "                                               overwrite=overwrite, _read_if_exists=read)\n",
    "\n",
    "downsampled_mt = mt.semi_join_cols(sample_set_02_ht)\n",
    "downsampled_mt = downsampled_mt.repartition(8)\n",
    "downsampled_mt = downsampled_mt.checkpoint(f'{gcs_prefix}/downsampled-{N}/set-02/gt.mt', \n",
    "                                           overwrite=overwrite, _read_if_exists=read)\n",
    "print(downsampled_mt.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfae5e8",
   "metadata": {},
   "source": [
    "Check that the two sample sets are disjoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2c1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_set_01_ht = hl.read_table(f'{gcs_prefix}/downsampled-{N}/set-01/samples.ht')\n",
    "sample_set_02_ht = hl.read_table(f'{gcs_prefix}/downsampled-{N}/set-02/samples.ht')\n",
    "\n",
    "set01 = set(sample_set_01_ht.collect())\n",
    "print(f'Sample set 01, count: {len(set01)}.')\n",
    "\n",
    "set02 = set(sample_set_02_ht.collect())\n",
    "print(f'Sample set 02, count: {len(set02)}.')\n",
    "\n",
    "print(f'Intersection of set 01 and set 02, count: {len(set01.intersection(set02))}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8842ee1a",
   "metadata": {},
   "source": [
    "## Create GRM for 10k samples and compute spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54655c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_prefix = 'gs://ukb-data/genotypes/406696-samples'\n",
    "N = 10000\n",
    "set_n = '02'\n",
    "overwrite = True\n",
    "parity = 'full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e782a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_mt = hl.read_matrix_table(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/gt.mt')\n",
    "m_variants = downsampled_mt.count()[0]\n",
    "for whiten_ws in [0, 30, 100]:\n",
    "    print(f'w = {whiten_ws}, {parity}.')\n",
    "    if whiten_ws == 0:\n",
    "        tsm = _make_tsm_from_call(\n",
    "            call_expr=downsampled_mt.GT,\n",
    "            block_size=1000, \n",
    "            partition_size=1000, \n",
    "            hwe_normalize=True\n",
    "        )\n",
    "    elif whiten_ws == 30:\n",
    "        tsm = _make_tsm_from_call(\n",
    "            call_expr=downsampled_mt.GT,\n",
    "            block_size=30, \n",
    "            partition_size=900, \n",
    "            hwe_normalize=True,\n",
    "            whiten_window_size=whiten_ws, \n",
    "            whiten_block_size=64\n",
    "        )\n",
    "    elif whiten_ws == 100:\n",
    "        tsm = _make_tsm_from_call(\n",
    "            call_expr=downsampled_mt.GT,\n",
    "            block_size=100, \n",
    "            partition_size=1000, \n",
    "            hwe_normalize=True,\n",
    "            whiten_window_size=whiten_ws, \n",
    "            whiten_block_size=64\n",
    "        )\n",
    "    t = tsm.block_table\n",
    "    block = tsm.block_expr\n",
    "\n",
    "    print(f'w = {whiten_ws}, {parity}: Computing GRM...')\n",
    "    grm = t.aggregate(hl.agg.ndarray_sum(block.T @ block)) / m_variants\n",
    "    grm_bm = hl.linalg.BlockMatrix.from_numpy(grm)\n",
    "    grm_bm.write(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-grm-ws{whiten_ws}.bm', overwrite=overwrite)\n",
    "    \n",
    "    print(f'w = {whiten_ws}, {parity}: Computing full spectrum...')\n",
    "    grm_bm = hl.linalg.BlockMatrix.read(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-grm-ws{whiten_ws}.bm')\n",
    "    eigvals = np.linalg.eigvalsh(grm_bm.to_numpy())\n",
    "    eigvals_bm = hl.linalg.BlockMatrix.from_numpy(eigvals[::-1])\n",
    "    eigvals_bm.write(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-grm-ws{whiten_ws}-eigenvalues.bm', overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75103505",
   "metadata": {},
   "source": [
    "## Create GRM for 10k samples (odd/even split) and compute spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d61560",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_prefix = 'gs://ukb-data/genotypes/406696-samples'\n",
    "N = 10000\n",
    "set_n = '02'\n",
    "overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627a28c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for parity in ['odd', 'even']:\n",
    "    downsampled_mt = hl.read_matrix_table(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/gt.mt')\n",
    "    if parity == 'odd':\n",
    "        downsampled_mt = downsampled_mt.filter_rows(hl.int(downsampled_mt.locus.contig.replace('chr', '')) % 2 != 0)\n",
    "    if parity == 'even':\n",
    "        downsampled_mt = downsampled_mt.filter_rows(hl.int(downsampled_mt.locus.contig.replace('chr', '')) % 2 == 0)\n",
    "\n",
    "    m_variants = downsampled_mt.count()[0]\n",
    "    for whiten_ws in [0, 30, 100]:\n",
    "        print(f'w = {whiten_ws}, {parity}.')\n",
    "        if whiten_ws == 0:\n",
    "            tsm = _make_tsm_from_call(\n",
    "                call_expr=downsampled_mt.GT,\n",
    "                block_size=1000, \n",
    "                partition_size=1000, \n",
    "                hwe_normalize=True\n",
    "            )\n",
    "        elif whiten_ws == 30:\n",
    "            tsm = _make_tsm_from_call(\n",
    "                call_expr=downsampled_mt.GT,\n",
    "                block_size=30, \n",
    "                partition_size=900, \n",
    "                hwe_normalize=True,\n",
    "                whiten_window_size=whiten_ws, \n",
    "                whiten_block_size=64\n",
    "            )\n",
    "        elif whiten_ws == 100:\n",
    "            tsm = _make_tsm_from_call(\n",
    "                call_expr=downsampled_mt.GT,\n",
    "                block_size=100, \n",
    "                partition_size=1000, \n",
    "                hwe_normalize=True,\n",
    "                whiten_window_size=whiten_ws, \n",
    "                whiten_block_size=64\n",
    "            )\n",
    "        t = tsm.block_table\n",
    "        block = tsm.block_expr\n",
    "\n",
    "        print(f'w = {whiten_ws}, {parity}: Computing GRM...')\n",
    "        grm = t.aggregate(hl.agg.ndarray_sum(block.T @ block)) / m_variants\n",
    "        grm_bm = hl.linalg.BlockMatrix.from_numpy(grm)\n",
    "        grm_bm.write(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-grm-ws{whiten_ws}.bm', overwrite=overwrite)\n",
    "\n",
    "        print(f'w = {whiten_ws}, {parity}: Computing full spectrum...')\n",
    "        grm_bm = hl.linalg.BlockMatrix.read(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-grm-ws{whiten_ws}.bm')\n",
    "        eigvals = np.linalg.eigvalsh(grm_bm.to_numpy())\n",
    "        eigvals_bm = hl.linalg.BlockMatrix.from_numpy(eigvals[::-1])\n",
    "        eigvals_bm.write(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-grm-ws{whiten_ws}-eigenvalues.bm', overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74694cdf",
   "metadata": {},
   "source": [
    "## Create GRM for 30k samples with manual blocking:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62134f2c",
   "metadata": {},
   "source": [
    "### Compute GRM blocks (block size = 10k) on the 30k samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b844e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_prefix = 'gs://ukb-data/genotypes/406696-samples'\n",
    "N = 30000\n",
    "set_n = '01'\n",
    "overwrite = True\n",
    "parity = 'full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_mt = hl.read_matrix_table(f'{gcs_prefix}/set-{set_n}/downsampled-{N}/gt.mt')\n",
    "# Filter to odd/even chromosomes, if required\n",
    "if parity == 'odd':\n",
    "    downsampled_mt = downsampled_mt.filter_rows(hl.int(downsampled_mt.locus.contig.replace('chr', '')) % 2 != 0)\n",
    "if parity == 'even':\n",
    "    downsampled_mt = downsampled_mt.filter_rows(hl.int(downsampled_mt.locus.contig.replace('chr', '')) % 2 == 0)\n",
    "\n",
    "for whiten_ws in [0, 30, 100]:\n",
    "    if whiten_ws == 0:\n",
    "        tsm = _make_tsm_from_call(\n",
    "            call_expr=downsampled_mt.GT,\n",
    "            block_size=1000, \n",
    "            partition_size=1000, \n",
    "            hwe_normalize=True\n",
    "        )\n",
    "    elif whiten_ws == 30:\n",
    "        tsm = _make_tsm_from_call(\n",
    "            call_expr=downsampled_mt.GT,\n",
    "            block_size=30, \n",
    "            partition_size=900, \n",
    "            hwe_normalize=True,\n",
    "            whiten_window_size=whiten_ws, \n",
    "            whiten_block_size=64\n",
    "        )\n",
    "    elif whiten_ws == 100:\n",
    "        tsm = _make_tsm_from_call(\n",
    "            call_expr=downsampled_mt.GT,\n",
    "            block_size=100, \n",
    "            partition_size=1000, \n",
    "            hwe_normalize=True,\n",
    "            whiten_window_size=whiten_ws, \n",
    "            whiten_block_size=64\n",
    "        )\n",
    "    t = tsm.block_table\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if i >= j:\n",
    "                print(f'i = {i}, j = {j}: block_i slice [:, {i*10000}:{(i+1)*10000}], block_j slice [:, {j*10000}:{(j+1)*10000}].')\n",
    "                block_i = tsm.block_expr[:, i*10000:(i+1)*10000]\n",
    "                block_j = tsm.block_expr[:, j*10000:(j+1)*10000]\n",
    "                grm_ij = t.aggregate(hl.agg.ndarray_sum(block_i.T @ block_j))\n",
    "                grm_ij_bm = hl.linalg.BlockMatrix.from_numpy(grm_ij)\n",
    "                grm_ij_bm.checkpoint(\n",
    "                    f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-grm-ws{whiten_ws}-block_{i}{j}.bm',\n",
    "                    overwrite=overwrite\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9393295a",
   "metadata": {},
   "source": [
    "### Concatenate GRM blocks into the full GRM, write out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d31010",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_prefix = 'gs://ukb-data/genotypes/406696-samples'\n",
    "N = 30000\n",
    "set_n = '01'\n",
    "overwrite = True\n",
    "parity = 'full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da706eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_mt = hl.read_matrix_table(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/gt.mt')\n",
    "if parity == 'odd':\n",
    "    downsampled_mt = downsampled_mt.filter_rows(hl.int(downsampled_mt.locus.contig.replace('chr', '')) % 2 != 0)\n",
    "if parity == 'even':\n",
    "    downsampled_mt = downsampled_mt.filter_rows(hl.int(downsampled_mt.locus.contig.replace('chr', '')) % 2 == 0)\n",
    "m_variants = downsampled_mt.count()[0]\n",
    "\n",
    "for whiten_ws in [0, 30, 100]:\n",
    "    # Read in each block from GCS \n",
    "    grm_00_bm = hl.linalg.BlockMatrix.read(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-grm-ws{whiten_ws}-block_00.bm')\n",
    "    grm_10_bm = hl.linalg.BlockMatrix.read(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-grm-ws{whiten_ws}-block_10.bm')\n",
    "    grm_11_bm = hl.linalg.BlockMatrix.read(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-grm-ws{whiten_ws}-block_11.bm')\n",
    "    grm_20_bm = hl.linalg.BlockMatrix.read(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-grm-ws{whiten_ws}-block_20.bm')\n",
    "    grm_21_bm = hl.linalg.BlockMatrix.read(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-grm-ws{whiten_ws}-block_21.bm')\n",
    "    grm_22_bm = hl.linalg.BlockMatrix.read(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-grm-ws{whiten_ws}-block_22.bm')\n",
    "\n",
    "    # Convert blocks to numpy arrays\n",
    "    grm_22_np = grm_22_bm.to_numpy()\n",
    "    grm_21_np = grm_21_bm.to_numpy()\n",
    "    grm_20_np = grm_20_bm.to_numpy()\n",
    "    grm_12_np = grm_21_np.T\n",
    "    grm_11_np = grm_11_bm.to_numpy()\n",
    "    grm_10_np = grm_10_bm.to_numpy()\n",
    "    grm_02_np = grm_20_np.T\n",
    "    grm_01_np = grm_10_np.T\n",
    "    grm_00_np = grm_00_bm.to_numpy()\n",
    "\n",
    "    # Horizontally stack the (10000, 10000) blocks (i0, i1, i2) into a single larger (10000, 30000) block\n",
    "    grm_0j_np = np.hstack((grm_00_np, grm_01_np, grm_02_np))\n",
    "    grm_1j_np = np.hstack((grm_10_np, grm_11_np, grm_12_np))\n",
    "    grm_2j_np = np.hstack((grm_20_np, grm_21_np, grm_22_np))\n",
    "    print(f'grm_0j_np shape = {grm_0j_np.shape}.')\n",
    "    print(f'grm_1j_np shape = {grm_1j_np.shape}.')\n",
    "    print(f'grm_2j_np shape = {grm_2j_np.shape}.')\n",
    "\n",
    "    # Vertically stack the (10000, 30000) blocks from above into the full GRM with shape (30000, 30000)\n",
    "    grm_np = np.vstack((grm_0j_np, grm_1j_np, grm_2j_np)) / m_variants\n",
    "    print(f'grm_np shape = {grm_np.shape}.')\n",
    "\n",
    "    # Convert full GRM to BlockMatrix and write to GCS\n",
    "    grm_bm = hl.linalg.BlockMatrix.from_numpy(grm_np)\n",
    "    grm_bm.write(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-grm-ws{whiten_ws}.bm', overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc50f3",
   "metadata": {},
   "source": [
    "### Read in the GRM BlockMatrix, compute full spectrum (all eigenvalues):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a920648",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_prefix = 'gs://ukb-data/genotypes/406696-samples'\n",
    "N = 30000\n",
    "set_n = '01'\n",
    "overwrite = True\n",
    "parity = 'full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for whiten_ws in [0, 30, 100]:\n",
    "    print(f'{parity}, w = {whiten_ws}.')\n",
    "    grm_bm = hl.linalg.BlockMatrix.read(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-grm-ws{whiten_ws}.bm')\n",
    "    eigvals = np.linalg.eigvalsh(grm_bm.to_numpy())\n",
    "    eigvals_bm = hl.linalg.BlockMatrix.from_numpy(eigvals[::-1])\n",
    "    eigvals_bm.write(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-grm-ws{whiten_ws}-eigenvalues.bm', overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736e7ba4",
   "metadata": {},
   "source": [
    "## Run PCA/SM estimator on the 10k/30k samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedd435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_prefix = 'gs://ukb-data/genotypes/406696-samples'\n",
    "N = 10000\n",
    "set_n = '02'\n",
    "parity = 'full'\n",
    "overwrite = False\n",
    "\n",
    "k = 100\n",
    "n_parts_scores = 4\n",
    "n_parts_loadings = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d65d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_mt = hl.read_matrix_table(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/gt.mt')\n",
    "m_variants, n_samples = downsampled_mt.count()\n",
    "for whiten_ws in [0, 30, 100]:\n",
    "    print(f'w = {whiten_ws}.')\n",
    "    if whiten_ws == 0:\n",
    "        tsm = _make_tsm_from_call(\n",
    "            call_expr=downsampled_mt.GT,\n",
    "            block_size=1000, \n",
    "            partition_size=1000, \n",
    "            hwe_normalize=True\n",
    "        )\n",
    "    elif whiten_ws == 30:\n",
    "        tsm = _make_tsm_from_call(\n",
    "            call_expr=downsampled_mt.GT,\n",
    "            block_size=30, \n",
    "            partition_size=900, \n",
    "            hwe_normalize=True,\n",
    "            whiten_window_size=whiten_ws, \n",
    "            whiten_block_size=64\n",
    "        )\n",
    "    elif whiten_ws == 100:\n",
    "        tsm = _make_tsm_from_call(\n",
    "            call_expr=downsampled_mt.GT,\n",
    "            block_size=100, \n",
    "            partition_size=1000, \n",
    "            hwe_normalize=True,\n",
    "            whiten_window_size=whiten_ws, \n",
    "            whiten_block_size=64\n",
    "        )\n",
    "\n",
    "    # Run PCA/SM on TSM\n",
    "    eigvals, scores, loadings, moments, stderrs = _pca_and_moments(\n",
    "        tsm, \n",
    "        k=k, \n",
    "        num_moments=10, \n",
    "        compute_loadings=True, \n",
    "        q_iterations=10, \n",
    "        oversampling_param=10, \n",
    "        moment_samples=100\n",
    "    )\n",
    "\n",
    "    # Set the 0th spectral moment = n_samples, and the 0th standard error = missing\n",
    "    eigvals = list(eigvals)\n",
    "    moments = [n_samples] + list(moments)\n",
    "    stderrs = hl.literal([None] + list(stderrs), 'array<float64>')\n",
    "\n",
    "    scores_ht = f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-scores-ws{whiten_ws}-k{k}.ht'\n",
    "    scores = scores.annotate_globals(\n",
    "        name=scores_ht,\n",
    "        eigenvalues=eigvals,\n",
    "        spectral_moments=moments,\n",
    "        standard_errors=stderrs,\n",
    "        m_variants=m_variants,\n",
    "        n_samples=n_samples\n",
    "    )\n",
    "    scores = scores.naive_coalesce(n_parts_scores)\n",
    "    scores.write(scores_ht, overwrite=overwrite)\n",
    "\n",
    "    loadings_ht = f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-loadings-ws{whiten_ws}-k{k}.ht'\n",
    "    loadings = loadings.annotate_globals(\n",
    "        name=loadings_ht,\n",
    "        eigenvalues=eigvals,\n",
    "        spectral_moments=moments,\n",
    "        standard_errors=stderrs,\n",
    "        m_variants=m_variants,\n",
    "        n_samples=n_samples\n",
    "    )\n",
    "    loadings = loadings.naive_coalesce(n_parts_loadings)\n",
    "    loadings.write(loadings_ht, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a1c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_prefix = 'gs://ukb-data/genotypes/406696-samples'\n",
    "N = 10000\n",
    "set_n = '02'\n",
    "overwrite = False\n",
    "\n",
    "k = 100\n",
    "n_parts_scores = 4\n",
    "n_parts_loadings = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8018cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for parity in ['odd', 'even']:\n",
    "    downsampled_mt = hl.read_matrix_table(f'{gcs_prefix}/downsampled-{N}/set-{set_n}/gt.mt')\n",
    "    if parity == 'odd':\n",
    "        downsampled_mt = downsampled_mt.filter_rows(hl.int(downsampled_mt.locus.contig.replace('chr', '')) % 2 != 0)\n",
    "    if parity == 'even':\n",
    "        downsampled_mt = downsampled_mt.filter_rows(hl.int(downsampled_mt.locus.contig.replace('chr', '')) % 2 == 0)\n",
    "\n",
    "    m_variants, n_samples = downsampled_mt.count()\n",
    "    for whiten_ws in [0, 30, 100]:\n",
    "        print(f'w = {whiten_ws}.')\n",
    "        if whiten_ws == 0:\n",
    "            tsm = _make_tsm_from_call(\n",
    "                call_expr=downsampled_mt.GT,\n",
    "                block_size=1000, \n",
    "                partition_size=1000, \n",
    "                hwe_normalize=True\n",
    "            )\n",
    "        elif whiten_ws == 30:\n",
    "            tsm = _make_tsm_from_call(\n",
    "                call_expr=downsampled_mt.GT,\n",
    "                block_size=30, \n",
    "                partition_size=900, \n",
    "                hwe_normalize=True,\n",
    "                whiten_window_size=whiten_ws, \n",
    "                whiten_block_size=64\n",
    "            )\n",
    "        elif whiten_ws == 100:\n",
    "            tsm = _make_tsm_from_call(\n",
    "                call_expr=downsampled_mt.GT,\n",
    "                block_size=100, \n",
    "                partition_size=1000, \n",
    "                hwe_normalize=True,\n",
    "                whiten_window_size=whiten_ws, \n",
    "                whiten_block_size=64\n",
    "            )\n",
    "\n",
    "        # Run PCA/SM on TSM\n",
    "        eigvals, scores, loadings, moments, stderrs = _pca_and_moments(\n",
    "            tsm, \n",
    "            k=k, \n",
    "            num_moments=10, \n",
    "            compute_loadings=True, \n",
    "            q_iterations=10, \n",
    "            oversampling_param=10, \n",
    "            moment_samples=100\n",
    "        )\n",
    "\n",
    "        # Set the 0th spectral moment = n_samples, and the 0th standard error = missing\n",
    "        eigvals = list(eigvals)\n",
    "        moments = [n_samples] + list(moments)\n",
    "        stderrs = hl.literal([None] + list(stderrs), 'array<float64>')\n",
    "\n",
    "        scores_ht = f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-scores-ws{whiten_ws}-k{k}.ht'\n",
    "        scores = scores.annotate_globals(\n",
    "            name=scores_ht,\n",
    "            eigenvalues=eigvals,\n",
    "            spectral_moments=moments,\n",
    "            standard_errors=stderrs,\n",
    "            m_variants=m_variants,\n",
    "            n_samples=n_samples\n",
    "        )\n",
    "        scores = scores.naive_coalesce(n_parts_scores)\n",
    "        scores.write(scores_ht, overwrite=overwrite)\n",
    "\n",
    "        loadings_ht = f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-loadings-ws{whiten_ws}-k{k}.ht'\n",
    "        loadings = loadings.annotate_globals(\n",
    "            name=loadings_ht,\n",
    "            eigenvalues=eigvals,\n",
    "            spectral_moments=moments,\n",
    "            standard_errors=stderrs,\n",
    "            m_variants=m_variants,\n",
    "            n_samples=n_samples\n",
    "        )\n",
    "        loadings = loadings.naive_coalesce(n_parts_loadings)\n",
    "        loadings.write(loadings_ht, overwrite=overwrite)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64821ba",
   "metadata": {},
   "source": [
    "# On local machine\n",
    "\n",
    "## Read eigenvalues and write out to CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b36962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "import hail as hl\n",
    "\n",
    "hl.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e206422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_prefix = 'gs://ukb-data/genotypes/406696-samples'\n",
    "N = 10000\n",
    "set_n = '02'\n",
    "parity = 'full'\n",
    "\n",
    "output_dir = '/Users/pcumming/pca/UKB/hdpca'\n",
    "pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for parity in ['full', 'odd', 'even']:\n",
    "    for whiten_ws in [0, 30, 100]:\n",
    "        print(f'{parity}, w = {whiten_ws}.')\n",
    "        eigenvalues_bm = hl.linalg.BlockMatrix.read(\n",
    "            f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-grm-ws{whiten_ws}-eigenvalues.bm'\n",
    "        )\n",
    "        eigenvalues_np = eigenvalues_bm.to_numpy()[0].T\n",
    "        np.savetxt(\n",
    "            f'{output_dir}/{parity}-{N}-set-{set_n}-grm-ws{whiten_ws}-eigenvalues.csv', \n",
    "            eigenvalues_np, \n",
    "            delimiter=','\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23216dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_prefix = 'gs://ukb-data/genotypes/406696-samples'\n",
    "N = 30000\n",
    "set_n = '01'\n",
    "parity = 'full'\n",
    "\n",
    "output_dir = '/Users/pcumming/pca/UKB/hdpca'\n",
    "pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for whiten_ws in [0, 30, 100]:\n",
    "    print(f'{parity}, w = {whiten_ws}.')\n",
    "    eigenvalues_bm = hl.linalg.BlockMatrix.read(\n",
    "        f'{gcs_prefix}/downsampled-{N}/set-{set_n}/{parity}-grm-ws{whiten_ws}-eigenvalues.bm'\n",
    "    )\n",
    "    eigenvalues_np = eigenvalues_bm.to_numpy()[0].T\n",
    "    np.savetxt(\n",
    "        f'{output_dir}/{parity}-{N}-set-{set_n}-grm-ws{whiten_ws}-eigenvalues.csv', \n",
    "        eigenvalues_np, \n",
    "        delimiter=','\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0312cb20",
   "metadata": {},
   "source": [
    "## Functions to load hdpca results from GCS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75885fac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T16:36:57.320077Z",
     "start_time": "2022-04-01T16:36:50.958660Z"
    }
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import hail as hl\n",
    "import json\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "hl.init(spark_conf={'spark.driver.memory': '12g'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc567e35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T16:36:57.409969Z",
     "start_time": "2022-04-01T16:36:57.322836Z"
    }
   },
   "outputs": [],
   "source": [
    "# Valid argument values to pass to load_hdpc_est:\n",
    "#     n_samples = 10000, 30000\n",
    "#     window_size = 0, 30, 100\n",
    "#     method = 'dgsp', 'lgsp', 'osp'\n",
    "# The default method used in hdpc_est is `dgsp`\n",
    "\n",
    "def load_hdpc_est(n_samples, sample_set, window_size, method, parity='full'):\n",
    "    valid_n_samples = [10000, 30000]\n",
    "    valid_window_sizes = [0, 30, 100]\n",
    "    valid_methods = ['dgsp', 'lgsp', 'osp']\n",
    "    assert n_samples in valid_n_samples, f'valid n_samples values: {valid_n_samples}.'\n",
    "    assert window_size in valid_window_sizes, f'valid window_size values: {valid_window_sizes}.'\n",
    "    assert method in valid_methods, f'valid method values: {valid_methods}.'\n",
    "\n",
    "    if sample_set == 2 or parity in ['odd', 'even']:\n",
    "        assert n_samples == 10000 and sample_set == 2, 'must set n_samples=10000 and sample_set=2 when parity=\\'odd\\' or parity=\\'even\\'.'\n",
    "\n",
    "    gcs_prefix = 'genotypes/406696-samples/hdpca'\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket('ukb-data')\n",
    "    blob = bucket.blob(f'{gcs_prefix}/hdpc_est-{parity}-{n_samples}-set-0{sample_set}-ws{window_size}-{method}.json')\n",
    "    hdpc_est_results = json.loads(blob.download_as_string())\n",
    "    hdpc_est_results['method'] = method\n",
    "    return hdpc_est_results\n",
    "\n",
    "\n",
    "def load_downsampled_ukb_scores(n_samples, sample_set, window_size, k, parity='full'):\n",
    "    valid_n_samples = [10000, 30000]\n",
    "    valid_window_sizes = [0, 30, 100]\n",
    "    valid_ks = [100]\n",
    "    assert n_samples in valid_n_samples, f'valid n_samples values: {valid_n_samples}.'\n",
    "    assert window_size in valid_window_sizes, f'valid window_size values: {valid_window_sizes}.'\n",
    "    assert k in valid_ks, f'valid k values: {valid_ks}.'\n",
    "\n",
    "    if sample_set == 2 or parity in ['odd', 'even']:\n",
    "        assert n_samples == 10000 and sample_set == 2, 'must set n_samples=10000 and sample_set=2 when parity=\\'odd\\' or parity=\\'even\\'.'\n",
    "\n",
    "    gcs_prefix = f'gs://ukb-data/genotypes/406696-samples/downsampled-{n_samples}/set-0{sample_set}'\n",
    "    ht = hl.read_table(f'{gcs_prefix}/{parity}-scores-ws{window_size}-k{k}.ht')\n",
    "    scores = np.array(ht.scores.collect()).T\n",
    "    return scores\n",
    "\n",
    "\n",
    "def load_downsampled_ukb_loadings(n_samples, sample_set, window_size, k, parity='full'):\n",
    "    valid_n_samples = [10000, 30000]\n",
    "    valid_window_sizes = [0, 30, 100]\n",
    "    valid_ks = [100]\n",
    "    assert n_samples in valid_n_samples, f'valid n_samples values: {valid_n_samples}.'\n",
    "    assert window_size in valid_window_sizes, f'valid window_size values: {valid_window_sizes}.'\n",
    "    assert k in valid_ks, f'valid k values: {valid_ks}.'\n",
    "\n",
    "    if sample_set == 2 or parity in ['odd', 'even']:\n",
    "        assert n_samples == 10000 and sample_set == 2, 'must set n_samples=10000 and sample_set=2 when parity=\\'odd\\' or parity=\\'even\\'.'\n",
    "\n",
    "    gcs_prefix = f'gs://ukb-data/genotypes/406696-samples/downsampled-{n_samples}/set-0{sample_set}'\n",
    "    ht = hl.read_table(f'{gcs_prefix}/{parity}-loadings-ws{window_size}-k{k}.ht')\n",
    "    loadings = np.array(ht.loadings.collect())\n",
    "    return loadings\n",
    "\n",
    "\n",
    "def load_downsampled_ukb_globals(n_samples, sample_set, window_size, k, parity='full'):\n",
    "    valid_n_samples = [10000, 30000]\n",
    "    valid_window_sizes = [0, 30, 100]\n",
    "    valid_ks = [100]\n",
    "    assert n_samples in valid_n_samples, f'valid n_samples values: {valid_n_samples}.'\n",
    "    assert window_size in valid_window_sizes, f'valid window_size values: {valid_window_sizes}.'\n",
    "    assert k in valid_ks, f'valid k values: {valid_ks}.'\n",
    "\n",
    "    if sample_set == 2 or parity in ['odd', 'even']:\n",
    "        assert n_samples == 10000 and sample_set == 2, 'must set n_samples=10000 and sample_set=2 when parity=\\'odd\\' or parity=\\'even\\'.'\n",
    "\n",
    "    gcs_prefix = f'gs://ukb-data/genotypes/406696-samples/downsampled-{n_samples}/set-0{sample_set}'\n",
    "    ht = hl.read_table(f'{gcs_prefix}/{parity}-scores-ws{window_size}-k{k}.ht')\n",
    "    eigvals = np.array(hl.eval(ht.eigenvalues))\n",
    "    spectral_moments = np.array(hl.eval(ht.spectral_moments))\n",
    "    std_errs = np.array(hl.eval(ht.standard_errors))\n",
    "    m_variants = hl.eval(ht.m_variants)\n",
    "    return eigvals, spectral_moments, std_errs, m_variants\n",
    "\n",
    "\n",
    "def load_downsampled_ukb_spectrum(n_samples, sample_set, window_size, k, parity='full'):\n",
    "    valid_n_samples = [10000, 30000]\n",
    "    valid_window_sizes = [0, 30, 100]\n",
    "    valid_ks = [100]\n",
    "    assert n_samples in valid_n_samples, f'valid n_samples values: {valid_n_samples}.'\n",
    "    assert window_size in valid_window_sizes, f'valid window_size values: {valid_window_sizes}.'\n",
    "    assert k in valid_ks, f'valid k values: {valid_ks}.'\n",
    "\n",
    "    if sample_set == 2 or parity in ['odd', 'even']:\n",
    "        assert n_samples == 10000 and sample_set == 2, 'must set n_samples=10000 and sample_set=2 when parity=\\'odd\\' or parity=\\'even\\'.'\n",
    "\n",
    "    gcs_prefix = f'gs://ukb-data/genotypes/406696-samples/downsampled-{n_samples}/set-0{sample_set}'\n",
    "    eigenvalues_bm = hl.linalg.BlockMatrix.read(f'{gcs_prefix}/{parity}-grm-ws{window_size}-eigenvalues.bm')\n",
    "    eigenvalues_np = eigenvalues_bm.to_numpy()[0]\n",
    "    return eigenvalues_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e84f20c-0ffa-4f4c-a9d0-3a42bb4dbb35",
   "metadata": {},
   "source": [
    "### Quick check to verify functions work as intended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2300238d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w = 0  # 0, 30, 100\n",
    "\n",
    "# To load hdpc_est results, set sample_set=2 for the odd/even split\n",
    "hdpc_est_full = load_hdpc_est(n_samples=10000, sample_set=2, window_size=w, method='dgsp', parity='full')\n",
    "hdpc_est_even = load_hdpc_est(n_samples=10000, sample_set=2, window_size=w, method='dgsp', parity='even')\n",
    "hdpc_est_odd = load_hdpc_est(n_samples=10000, sample_set=2, window_size=w, method='dgsp', parity='odd')\n",
    "\n",
    "# To load PCA/SM scores, set sample_set=2 for the odd/even split\n",
    "scores_full = load_downsampled_ukb_scores(n_samples=10000, sample_set=2, window_size=w, k=100, parity='full')\n",
    "scores_even = load_downsampled_ukb_scores(n_samples=10000, sample_set=2, window_size=w, k=100, parity='even')\n",
    "scores_odd = load_downsampled_ukb_scores(n_samples=10000, sample_set=2, window_size=w, k=100, parity='odd')\n",
    "\n",
    "# To load PCA/SM loadings, set sample_set=2 for the odd/even split\n",
    "loadings_full = load_downsampled_ukb_loadings(n_samples=10000, sample_set=2, window_size=w, k=100, parity='full')\n",
    "loadings_even = load_downsampled_ukb_loadings(n_samples=10000, sample_set=2, window_size=w, k=100, parity='even')\n",
    "loadings_odd = load_downsampled_ukb_loadings(n_samples=10000, sample_set=2, window_size=w, k=100, parity='odd')\n",
    "\n",
    "# To load PCA/SM results (eigenvalues, spectral moments, standard errors, variant count), set sample_set=2 for the odd/even split\n",
    "evals_full, sm_full, stderr_full, m_full = load_downsampled_ukb_globals(n_samples=10000, sample_set=2, window_size=w, k=100, parity='full')\n",
    "evals_even, sm_even, stderr_even, m_even = load_downsampled_ukb_globals(n_samples=10000, sample_set=2, window_size=w, k=100, parity='even')\n",
    "evals_odd, sm_odd, stderr_odd, m_odd = load_downsampled_ukb_globals(n_samples=10000, sample_set=2, window_size=w, k=100, parity='odd')\n",
    "\n",
    "# To load all GRM eigenvalues, set sample_set=2 for the odd/even split\n",
    "spectrum_full = load_downsampled_ukb_spectrum(n_samples=10000, sample_set=2, window_size=w, k=100, parity='full')\n",
    "spectrum_even = load_downsampled_ukb_spectrum(n_samples=10000, sample_set=2, window_size=w, k=100, parity='even')\n",
    "spectrum_odd = load_downsampled_ukb_spectrum(n_samples=10000, sample_set=2, window_size=w, k=100, parity='odd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab139941",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores_full.shape)\n",
    "print(loadings_full.shape)\n",
    "print()\n",
    "print(scores_odd.shape)\n",
    "print(loadings_odd.shape)\n",
    "print()\n",
    "print(scores_even.shape)\n",
    "print(loadings_even.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d9e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [10000, 30000]:\n",
    "    for ws in [0, 30, 100]:\n",
    "        for method in ['dgsp', 'lgsp', 'osp']:\n",
    "            print(load_hdpc_est(n_samples=n, window_size=ws, method=method))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77910bf-3bee-4cd2-9f82-493e9ab7ce0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute cross-correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eb39ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_crosscorr(nd1, nd2, k):\n",
    "    # Compute matrix of cross-correlations, take off-diagonal block, run SVD and return squared singular values\n",
    "    R = np.corrcoef(nd1, nd2)[:k, k:]\n",
    "    s = np.linalg.svd(R, compute_uv=False)\n",
    "    return s ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902214c7-9b1a-4ca4-9168-9753f8ae15de",
   "metadata": {},
   "source": [
    "### Cross-correlations between two disjoint 10k samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3224a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T16:43:06.901722Z",
     "start_time": "2022-04-01T16:40:09.129851Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 10000\n",
    "k = 100\n",
    "\n",
    "output_path = f'/Users/pcumming/pca/UKB/npy/406696-samples/downsampled-{n}'\n",
    "pathlib.Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Compute cross-correlations between sets 1 and 2 and write out results\n",
    "for w in [0, 30, 100]:\n",
    "    print(f'w = {w}.')\n",
    "    loadings_01 = load_downsampled_ukb_loadings(n_samples=n, sample_set=1, window_size=w, k=k, parity='full')\n",
    "    loadings_02 = load_downsampled_ukb_loadings(n_samples=n, sample_set=2, window_size=w, k=k, parity='full')\n",
    "    R = np.corrcoef(loadings_01.T, loadings_02.T)[:k, k:]\n",
    "    with open(f'{output_path}/set01_set02_cross_correlations-loadings-ws{w}-k{k}.npy', 'wb') as f:\n",
    "        np.save(f, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000bd18b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T16:43:26.103781Z",
     "start_time": "2022-04-01T16:43:26.093617Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read back in results from above\n",
    "for w in [0, 30, 100]:\n",
    "    print(f'w = {w}:')\n",
    "    with open(f'{output_path}/set01_set02_cross_correlations-loadings-ws{w}-k{k}.npy', 'rb') as f:\n",
    "        R = np.load(f)\n",
    "    print(R.shape)\n",
    "    print(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c1eb2-766a-428a-9002-a08fac65363a",
   "metadata": {},
   "source": [
    "### Odd/even chromosome cross-correlations for a single 10k sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45057cf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T16:01:31.254811Z",
     "start_time": "2022-04-01T16:00:11.273159Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 10000\n",
    "k = 100\n",
    "\n",
    "output_path = f'/Users/pcumming/pca/UKB/npy/406696-samples/downsampled-{n}/set-02'\n",
    "pathlib.Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Compute odd/even cross-correlations and write out results\n",
    "for w in [0, 30, 100]:\n",
    "    print(f'w = {w}.')\n",
    "    loadings_odd = load_downsampled_ukb_loadings(n_samples=n, sample_set=2, window_size=w, k=k, parity='odd')\n",
    "    loadings_even = load_downsampled_ukb_loadings(n_samples=n, sample_set=2, window_size=w, k=k, parity='even')\n",
    "    R = np.corrcoef(loadings_odd.T, loadings_odd.T)[:k, k:]\n",
    "    with open(f'{output_path}/odd_even_cross_correlations-loadings-ws{w}-k{k}.npy', 'wb') as f:\n",
    "        np.save(f, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e0dbc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T16:03:25.909266Z",
     "start_time": "2022-04-01T16:03:25.899508Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read back in results from above\n",
    "for w in [0, 30, 100]:\n",
    "    print(f'w = {w}:')\n",
    "    with open(f'{output_path}/odd_even_cross_correlations-loadings-ws{w}-k{k}.npy', 'rb') as f:\n",
    "        R = np.load(f)\n",
    "    print(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8ca55a-aa0a-4194-bf5c-9034da605d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
